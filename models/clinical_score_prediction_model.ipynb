{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "spFnEq5UK2l2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!!pip install -q git+https://github.com/keras-team/keras-nlp.git --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-DVh6OXTQ0HD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e4078d-9a6a-43d7-b3df-d48e693bdecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.regularizers import l2, l1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hKDvB83tgnP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ca4dd3-f169-4a4e-c31e-8261a3715430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "IYckdv4NisB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7214e3-aafa-46c4-ea12-645f715877a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max frames: 1515\n",
            "Number of temporal windows: 5 - temporal window size: 303\n"
          ]
        }
      ],
      "source": [
        "EXERCISE = 'Es1' # Use Es1, Es2, Es3, Es4, Es5, or All to train a model on all exercises\n",
        "\n",
        "# Mapping of exercise names to their maximum lengths\n",
        "max_length_mapping = {\n",
        "        \"Es1\": 1515,\n",
        "        \"Es2\": 1668,\n",
        "        \"Es3\": 1518,\n",
        "        \"Es4\": 1988,\n",
        "        \"Es5\": 1022\n",
        "    }\n",
        "\n",
        "# Mapping of exercise names to their temporal window configurations\n",
        "temporal_windows_mapping = { #[num_windows, window_size]\n",
        "        \"Es1\": [5,303],\n",
        "        \"Es2\": [3,556],\n",
        "        \"Es3\": [11,138],\n",
        "        \"Es4\": [4,497],\n",
        "        \"Es5\": [7,146],\n",
        "    }\n",
        "\n",
        "def get_max_length(exercise):\n",
        "  if exercise == \"All\":\n",
        "    return max(max_length_mapping.values())\n",
        "  else:\n",
        "    return max_length_mapping[exercise]\n",
        "\n",
        "def get_temporal_windows(exercise):\n",
        "  if exercise == \"All\":\n",
        "    max_es = max(max_length_mapping.keys(), key=max_length_mapping.get)\n",
        "    return temporal_windows_mapping[max_es]\n",
        "  else:\n",
        "    return temporal_windows_mapping[exercise]\n",
        "\n",
        "max_exercise_length = get_max_length(EXERCISE)\n",
        "temporal_windows = get_temporal_windows(EXERCISE)\n",
        "\n",
        "print(f\"Max frames: {max_exercise_length}\")\n",
        "print(f\"Number of temporal windows: {temporal_windows[0]} - temporal window size: {temporal_windows[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNf-wMRaJBzM"
      },
      "source": [
        "# Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "6wnPa4Xhd-K-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/rehab-ai-data/KiMoRe_final/KiMoRe_data_movenet_features.csv\")\n",
        "if EXERCISE != \"All\":\n",
        "  df = df[df['exercise']==EXERCISE]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "Yv5StjDkASZC",
        "outputId": "c801b2ef-d6fc-40c4-f6a7-e1c3f691dc19"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID exercise                                              video  \\\n",
              "2   P_ID11      Es1  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "8   P_ID16      Es1  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "14  P_ID10      Es1  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "18   P_ID4      Es1  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "24   P_ID3      Es1                                                NaN   \n",
              "\n",
              "                                      joint_positions  \\\n",
              "2   /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "8   /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "14  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "18  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...   \n",
              "24                                                NaN   \n",
              "\n",
              "                                       joint_features  clinical_score  #frames  \n",
              "2   /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...       14.666667      529  \n",
              "8   /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...       37.000000      702  \n",
              "14  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...       34.308180      606  \n",
              "18  /content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...       14.000000      842  \n",
              "24                                                NaN       -1.000000        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-443e22cf-ff95-4e76-9914-2231ca89784f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>exercise</th>\n",
              "      <th>video</th>\n",
              "      <th>joint_positions</th>\n",
              "      <th>joint_features</th>\n",
              "      <th>clinical_score</th>\n",
              "      <th>#frames</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P_ID11</td>\n",
              "      <td>Es1</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>P_ID16</td>\n",
              "      <td>Es1</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>P_ID10</td>\n",
              "      <td>Es1</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>34.308180</td>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>P_ID4</td>\n",
              "      <td>Es1</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>/content/drive/MyDrive/rehab-ai-data/KiMoRe_rg...</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>P_ID3</td>\n",
              "      <td>Es1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-443e22cf-ff95-4e76-9914-2231ca89784f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-443e22cf-ff95-4e76-9914-2231ca89784f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-443e22cf-ff95-4e76-9914-2231ca89784f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35a7148a-5ed6-48a6-b54a-2b3c4c9a9371\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35a7148a-5ed6-48a6-b54a-2b3c4c9a9371')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35a7148a-5ed6-48a6-b54a-2b3c4c9a9371 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "HL-VqavjeO6L"
      },
      "outputs": [],
      "source": [
        "def get_dataframe_cols():\n",
        "  KEYPOINT_DICT = {\n",
        "    'nose': 0,\n",
        "    'left_eye': 1,\n",
        "    'right_eye': 2,\n",
        "    'left_ear': 3,\n",
        "    'right_ear': 4,\n",
        "    'left_shoulder': 5,\n",
        "    'right_shoulder': 6,\n",
        "    'left_elbow': 7,\n",
        "    'right_elbow': 8,\n",
        "    'left_wrist': 9,\n",
        "    'right_wrist': 10,\n",
        "    'left_hip': 11,\n",
        "    'right_hip': 12,\n",
        "    'left_knee': 13,\n",
        "    'right_knee': 14,\n",
        "    'left_ankle': 15,\n",
        "    'right_ankle': 16\n",
        "  }\n",
        "  df_cols = []\n",
        "  for keypoint_name in KEYPOINT_DICT:\n",
        "    df_cols.append(f\"{keypoint_name}_y\")\n",
        "    df_cols.append(f\"{keypoint_name}_x\")\n",
        "    df_cols.append(f\"{keypoint_name}_confidence\")\n",
        "  return df_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "NFcjrZEEeUOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae56181a-b59f-4d22-be6c-0c355f0b4bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping 15 columns.\n"
          ]
        }
      ],
      "source": [
        "all_cols = get_dataframe_cols()\n",
        "face_cols = all_cols[:15]\n",
        "cols_drop = face_cols\n",
        "print(f\"Dropping {len(cols_drop)} columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "DiZas7ht2Zch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20367420-456e-4cb6-be81-50b333a956fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using exercise: Es1\n",
            "Maximum video length: 1515\n",
            "Smoothing window is set to 10.\n",
            "Joint positions data is being used.\n",
            "Joint positions data is being used without smoothing.\n",
            "Joint features data is not being used.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Using exercise: {EXERCISE}\")\n",
        "print(f\"Maximum video length: {max_exercise_length}\")\n",
        "\n",
        "# Settings for training configuration\n",
        "smoothing_window=10\n",
        "use_joint_positions=True\n",
        "use_joint_features=False\n",
        "smooth_joint_positions=False\n",
        "smooth_joint_features=False\n",
        "\n",
        "print(f\"Smoothing window is set to {smoothing_window}.\")\n",
        "print(f\"Joint positions data {'is' if use_joint_positions else 'is not'} being used.\")\n",
        "if use_joint_positions:\n",
        "  print(f\"Joint positions data is being used {'without' if not smooth_joint_positions else 'with'} smoothing.\")\n",
        "\n",
        "print(f\"Joint features data {'is' if use_joint_features else 'is not'} being used.\")\n",
        "if use_joint_features:\n",
        "  print(f\"Joint features data is being used {'without' if not smooth_joint_features else 'with'} smoothing.\")\n",
        "\n",
        "def prepare_data(df, exercise_video_max_len):\n",
        "  \"\"\"Prepares data for training or evaluation.\n",
        "\n",
        "  Args:\n",
        "    df: DataFrame containing exercise data.\n",
        "    exercise_video_max_len: Maximum length of exercise videos.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of (data, padding_masks), labels:\n",
        "      data: A NumPy array of shape (num_samples, max_length, num_features) containing prepared data.\n",
        "      padding_masks: A NumPy array of shape (num_samples, max_length) indicating padded elements.\n",
        "      labels: A NumPy array of shape (num_samples) containing clinical scores.\n",
        "  \"\"\"\n",
        "\n",
        "  # Ensure at least one data type is used\n",
        "  if not use_joint_positions and not use_joint_features:\n",
        "    print(\"At least one of use_joint_positions and use_joint_features should be True!\")\n",
        "    return None, None\n",
        "\n",
        "  data = []\n",
        "  labels = []\n",
        "  padding_masks = []\n",
        "  for index, row in df.iterrows():\n",
        "    joint_positions_path = row['joint_positions']\n",
        "    joint_features_path = row['joint_features']\n",
        "    if joint_positions_path is np.NAN:\n",
        "      continue\n",
        "    clinical_score = row['clinical_score']\n",
        "    video_length = row['#frames']\n",
        "\n",
        "    joint_positions_data = None\n",
        "    # Load joint positions data if needed\n",
        "    if use_joint_positions:\n",
        "        joint_positions_data = pd.read_csv(joint_positions_path)\n",
        "        joint_positions_data = joint_positions_data.drop(cols_drop, axis=1)\n",
        "        if smooth_joint_positions:\n",
        "          for col in joint_positions_data.columns:\n",
        "              joint_positions_data[col] = joint_positions_data[col].rolling(smoothing_window).mean()\n",
        "        joint_positions_data = joint_positions_data.to_numpy()\n",
        "\n",
        "    joint_features_data = None\n",
        "    # Load joint features data if needed\n",
        "    if use_joint_features:\n",
        "        joint_features_data = pd.read_csv(joint_features_path)\n",
        "        if smooth_joint_features:\n",
        "          for col in joint_features_data.columns:\n",
        "              joint_features_data[col] = joint_features_data[col].rolling(smoothing_window).mean()\n",
        "        joint_features_data = joint_features_data.to_numpy()\n",
        "\n",
        "    data_to_use = None\n",
        "    # Combine data if both are needed\n",
        "    if use_joint_positions and use_joint_features:\n",
        "        data_to_use = np.concatenate((joint_positions_data, joint_features_data), axis=1)\n",
        "    elif use_joint_positions:\n",
        "        data_to_use = joint_positions_data\n",
        "    else:\n",
        "        data_to_use = joint_features_data\n",
        "\n",
        "    # Pad data to fixed length and create padding masks\n",
        "    padding_length = exercise_video_max_len - video_length\n",
        "    padding_mask = np.zeros((video_length + padding_length))\n",
        "    padding_mask[-padding_length:] = 1 # Set padding elements to 1\n",
        "\n",
        "    # Pad data with zeros\n",
        "    data_to_use_padded = np.pad(data_to_use, ((0, padding_length), (0, 0)), mode='constant', constant_values=0)\n",
        "\n",
        "    data.append(data_to_use_padded)\n",
        "    labels.append(clinical_score)\n",
        "    padding_masks.append(padding_mask)\n",
        "\n",
        "  data = np.array(data)\n",
        "  labels = np.array(labels)\n",
        "  padding_masks = np.array(padding_masks)\n",
        "\n",
        "  data = np.nan_to_num(data) # Replace NaN values with numerical equivalents\n",
        "  labels = np.nan_to_num(labels)\n",
        "\n",
        "  print(\"Data Shape:\", data.shape)\n",
        "  print(\"Labels Shape:\", labels.shape)\n",
        "  print(\"Padding Masks Shape:\", padding_masks.shape)\n",
        "\n",
        "  return (data, padding_masks), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "8Q18qUHS4cqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8fd8da-3b32-42cd-8684-c33a6fbd96f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (72, 1515, 36)\n",
            "Labels Shape: (72,)\n",
            "Padding Masks Shape: (72, 1515)\n"
          ]
        }
      ],
      "source": [
        "(all_data, all_padding), all_labels = prepare_data(df, max_exercise_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OWozp_iJFBF"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "s7XvYuks25E6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74a16d9-4f4e-4673-e692-d1c6eb0b9c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data Columns: 36\n",
            "Number of Temporal Windows: 5\n",
            "Window Size: 303\n",
            "Number of Attention Heads: 4\n",
            "Intermediate Model Dimension: 9\n",
            "Learning Rate: 0.001\n"
          ]
        }
      ],
      "source": [
        "NUM_COLS = all_data[0].shape[1]\n",
        "NUM_WINDOWS = temporal_windows[0]\n",
        "WINDOW_SIZE = temporal_windows[1]\n",
        "NUM_HEADS = 4\n",
        "D_MODEL = NUM_COLS // 4\n",
        "if use_joint_features and not use_joint_positions:\n",
        "  D_MODEL = NUM_COLS // 2 # if using joint features only then NUM_COLS will already be small enough\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "print(f\"Input Data Columns: {NUM_COLS}\")\n",
        "print(f\"Number of Temporal Windows: {NUM_WINDOWS}\")\n",
        "print(f\"Window Size: {WINDOW_SIZE}\")\n",
        "print(f\"Number of Attention Heads: {NUM_HEADS}\")\n",
        "print(f\"Intermediate Model Dimension: {D_MODEL}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "YVxTX2ej7hkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a90070-1ddc-48d6-fb27-2db9bd927a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windows:\n",
            "(None, 303, 36)\n",
            "(None, 303, 36)\n",
            "(None, 303, 36)\n",
            "(None, 303, 36)\n",
            "(None, 303, 36)\n",
            "Windows Masks:\n",
            "(None, 303)\n",
            "(None, 303)\n",
            "(None, 303)\n",
            "(None, 303)\n",
            "(None, 303)\n",
            "Embeddings:\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "Positional Embeddings:\n",
            "(303, 9)\n",
            "(303, 9)\n",
            "(303, 9)\n",
            "(303, 9)\n",
            "(303, 9)\n",
            "All Embeddings:\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "Encodings:\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "(None, 303, 9)\n",
            "Concat: (None, 1515, 9)\n",
            "Flatten: (None, 13635)\n",
            "Final Dense: (None, 77)\n"
          ]
        }
      ],
      "source": [
        "# Define input layers for data and padding masks\n",
        "inputs = tf.keras.Input(shape=(all_data[0].shape[0], all_data[0].shape[1]), name='orignal_data')\n",
        "masks = tf.keras.Input(shape=(all_padding.shape[1]), name='padding_masks')\n",
        "\n",
        "# Split data into windows\n",
        "windows = tf.split(inputs, NUM_WINDOWS, axis=1)\n",
        "print(\"Windows:\")\n",
        "for window in windows:\n",
        "  print(window.shape)\n",
        "\n",
        "# Split masks into windows\n",
        "windows_masks = tf.split(masks, NUM_WINDOWS, axis=1)\n",
        "print(\"Windows Masks:\")\n",
        "for mask in windows_masks:\n",
        "  print(mask.shape)\n",
        "\n",
        "\n",
        "# Create embedding layers for temporal windows\n",
        "embedding_layer = tf.keras.layers.Dense(D_MODEL*2, activation='relu')\n",
        "if not use_joint_positions and use_joint_features:\n",
        "  embedding_layer = tf.keras.layers.Dense(D_MODEL, activation='relu')\n",
        "embedding_layer3 = tf.keras.layers.Dense(D_MODEL, activation='relu')\n",
        "\n",
        "# Apply embedding layers to each window\n",
        "embeddings = []\n",
        "for window in windows:\n",
        "    embedding = embedding_layer(window)\n",
        "    if use_joint_positions:\n",
        "      embedding = embedding_layer3(embedding)\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "print(\"Embeddings:\")\n",
        "for embd in embeddings:\n",
        "  print(embd.shape)\n",
        "\n",
        "# Create positional embeddings to encode position within windows\n",
        "positional_embedding_layer = tf.keras.layers.Embedding(input_dim=WINDOW_SIZE, output_dim=D_MODEL)\n",
        "positional_embeddings = []\n",
        "for i in range(NUM_WINDOWS):\n",
        "    positional_embedding = positional_embedding_layer(tf.range(WINDOW_SIZE))\n",
        "    positional_embeddings.append(positional_embedding)\n",
        "\n",
        "print(\"Positional Embeddings:\")\n",
        "for pos_embd in positional_embeddings:\n",
        "  print(pos_embd.shape)\n",
        "\n",
        "# Combine temporal and positional embeddings\n",
        "embeddings_all = [embedding + positional_embedding for embedding, positional_embedding in zip(embeddings, positional_embeddings)]\n",
        "print(\"All Embeddings:\")\n",
        "for embd in embeddings_all:\n",
        "  print(embd.shape)\n",
        "\n",
        "# Encode windows using a Transformer encoder\n",
        "transformer_encoder_layer = keras_nlp.layers.TransformerEncoder(intermediate_dim=D_MODEL, num_heads=NUM_HEADS)\n",
        "encoded = [transformer_encoder_layer(window_embd, window_mask) for window_embd, window_mask in zip(embeddings, windows_masks)]\n",
        "print(\"Encodings:\")\n",
        "for enc in encoded:\n",
        "  print(enc.shape)\n",
        "\n",
        "# Concatenate encoded windows and flatten\n",
        "concat_output = tf.concat(encoded, axis=1)\n",
        "print(f\"Concat: {concat_output.shape}\")\n",
        "flatten_output = tf.keras.layers.Flatten()(concat_output)\n",
        "print(f\"Flatten: {flatten_output.shape}\")\n",
        "\n",
        "# Dense layers before final prediction\n",
        "dense_output = tf.keras.layers.Dense(4970, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(flatten_output)\n",
        "dense_output = tf.keras.layers.Dense(621, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(dense_output)\n",
        "dense_output = tf.keras.layers.Dense(77, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(dense_output)\n",
        "print(f\"Final Dense: {dense_output.shape}\")\n",
        "output = tf.keras.layers.Dense(1)(dense_output)\n",
        "\n",
        "model = tf.keras.Model(inputs=[inputs, masks],\n",
        "                       outputs=output,\n",
        "                       name='transformer_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T69KPkAq9CTm"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_activations=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWH_ecsvMrPJ"
      },
      "source": [
        "# Plot Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "QHJnkSYmCO85"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(train_preds, train_labels, test_preds, test_labels, fold):\n",
        "  # Create a figure with two subplots\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.suptitle(f'{EXERCISE} - Fold {fold}',fontsize=20)\n",
        "\n",
        "  # Plot training set predictions and labels\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(train_preds, 's', color='red', label='Prediction', linestyle='None', alpha=0.5, markersize=6)\n",
        "  plt.plot(train_labels, 'o', color='green', label='Clinical Score', alpha=0.4, markersize=6)\n",
        "  plt.title('Training Set', fontsize=18)\n",
        "  plt.xlabel('Sequence Number', fontsize=16)\n",
        "  plt.ylabel('Clinical Score Scale', fontsize=16)\n",
        "  plt.legend(loc=3, prop={'size': 14})\n",
        "\n",
        "  # Plot testing set predictions and labels\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(test_preds, 's', color='red', label='Prediction', linestyle='None', alpha=0.5, markersize=6)\n",
        "  plt.plot(test_labels, 'o', color='green', label='Clinical Score', alpha=0.4, markersize=6)\n",
        "  plt.title('Testing Set', fontsize=18)\n",
        "  plt.xlabel('Sequence Number', fontsize=16)\n",
        "  plt.ylabel('Clinical Score Scale', fontsize=16)\n",
        "  plt.legend(loc=3, prop={'size': 14})\n",
        "\n",
        "  # Adjust layout and save figure\n",
        "  plt.tight_layout()\n",
        "  fig_title = f'{EXERCISE}_fold{fold}_pred_plot'\n",
        "  plt.savefig(f'/content/drive/MyDrive/rehab-ai-data/saved_models_images/temp/{fig_title}.png', dpi=300)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, ptype, fold=None):\n",
        "  # Extract the metric history for training\n",
        "  type_history = history.history[ptype]\n",
        "\n",
        "  epochs = range(len(type_history))\n",
        "  plt.plot(epochs, type_history, label=f'Training {ptype.capitalize()}')\n",
        "\n",
        "  # If a fold is specified, add validation history\n",
        "  if fold:\n",
        "    type_history_val = history.history[f'val_{ptype}']\n",
        "    plt.plot(epochs, type_history_val, label=f'Validation {ptype.capitalize()}')\n",
        "    plt.title(f'Training and Validation {ptype.capitalize()}')\n",
        "    plt.suptitle(f'{EXERCISE} - Fold {fold}')\n",
        "  else:\n",
        "    plt.title(f'{EXERCISE} {ptype.capitalize()}')\n",
        "\n",
        "  # Add labels and legend\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel(f'{ptype.capitalize()}')\n",
        "  plt.legend()\n",
        "\n",
        "  # Create and save the plot\n",
        "  fig_title = f'{EXERCISE}_{ptype}_plot'\n",
        "  if fold:\n",
        "    fig_title += f'_fold{fold}'\n",
        "  plt.savefig(f'/content/drive/MyDrive/rehab-ai-data/saved_models_images/temp/{fig_title}.png', dpi=300)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FRkyExWt597E"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SKVmZG7KXuM"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "ZU-t5LGjK6QZ"
      },
      "outputs": [],
      "source": [
        "class PrintEpochs(tf.keras.callbacks.Callback):\n",
        "    \"\"\"Prints progress for specific epochs during training.\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch in [1, 25, 50, 75, 100]:\n",
        "              values = \", \".join([f\"{key}: {value:.4f}\" for key, value in logs.items()])\n",
        "              print(f\"Epoch {epoch}: {values}\")\n",
        "\n",
        "def cross_validate(model, data, labels, padding_masks, k=5):\n",
        "  \"\"\"Performs k-fold cross-validation on the model.\"\"\"\n",
        "  y_true, y_pred, histories = list(), list(), list()\n",
        "  i = 1\n",
        "  kfold = KFold(n_splits=k, random_state=0, shuffle=True)\n",
        "  print(f\"Cross Validating Model Using {k} Folds...\")\n",
        "  for train_idx, val_idx in kfold.split(data):\n",
        "    print(f\"---------------- Fold {i} ----------------\")\n",
        "\n",
        "    # Split data for training and validation\n",
        "    X_train, X_val = data[train_idx], data[val_idx]\n",
        "    padding_train, padding_val = padding_masks[train_idx], padding_masks[val_idx]\n",
        "    y_train, y_val = labels[train_idx], labels[val_idx]\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse', metrics=['mae'])\n",
        "\n",
        "    history = model.fit([X_train, padding_train], y_train, epochs=100, validation_data=([X_val, padding_val], y_val), verbose=0, callbacks=[PrintEpochs()])\n",
        "\n",
        "    # Make predictions on training and validation sets\n",
        "    train_pred = model.predict([X_train, padding_train])\n",
        "    val_pred = model.predict([X_val, padding_val])\n",
        "\n",
        "    # Store true labels, predictions, and history for later analysis\n",
        "    y_true.extend(y_val)\n",
        "    y_pred.extend(val_pred)\n",
        "    histories.append(history)\n",
        "\n",
        "    # Calculate and print MAE for the fold\n",
        "    fold_mae = mean_absolute_error(y_val, val_pred)\n",
        "    print(f'- MAE of fold {i} = {fold_mae}')\n",
        "\n",
        "    plot_history(history, 'loss', i)\n",
        "    plot_history(history, 'mae', i)\n",
        "    plot_predictions(train_pred, y_train, val_pred, y_val, i)\n",
        "    i = i+1\n",
        "\n",
        "  # Calculate overall MAE across all folds\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  print(f'OOF MAE = {mae}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(model, all_data, all_labels, all_padding)"
      ],
      "metadata": {
        "id": "_pLfY2EKiSRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIvjd-B2kWCY"
      },
      "source": [
        "# Final Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "DlYkusHhtmKZ"
      },
      "outputs": [],
      "source": [
        "for i in range(len(model.weights)):\n",
        "    model.weights[i]._handle_name = str(i) + '__' + model.weights[i].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "er_gLdgsfpWt"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "lBF03UpfrhCF"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = f'/content/drive/MyDrive/rehab-ai-data/saved_models_weights/ml_model_{EXERCISE}_Weights.hdf5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_mae',\n",
        "    save_best_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjLeyf_vL7Zl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = model.fit([all_data, all_padding], all_labels, epochs=100,\n",
        "                     callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLSMwN2kC9L8"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijkj6_YC9FR3"
      },
      "source": [
        "# Model History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0-y50An75H7"
      },
      "outputs": [],
      "source": [
        "plot_history(history, 'loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e4aEz2Y8P_t"
      },
      "outputs": [],
      "source": [
        "plot_history(history, 'mae')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujIXQojSmSri"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzricXhemVVH"
      },
      "outputs": [],
      "source": [
        "model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfhLZFl1melq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80341ae9-416d-46a2-fe0d-27843f0d2678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p saved_model\n",
        "model.save(f'/content/drive/MyDrive/rehab-ai-data/saved_models_weights/ml_model_{EXERCISE}.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lIVERIqgxB2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}